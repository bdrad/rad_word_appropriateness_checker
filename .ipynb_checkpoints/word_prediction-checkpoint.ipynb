{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertConfig, AutoModelWithLMHead\n",
    "from scipy.spatial.distance import cosine\n",
    "import numpy as np\n",
    "import copy\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.3.1\n"
     ]
    }
   ],
   "source": [
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# bert-base-uncased\n",
    "bertconfig = BertConfig.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "basetokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "basemodel = BertForMaskedLM.from_pretrained('bert-base-uncased', config = bertconfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '[CLS] The [MASK] ran to the emergency room to see his patient.[SEP]'\n",
    "TOPK = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = basemodel\n",
    "tokenizer = basetokenizer\n",
    "tokenized_text = tokenizer.tokenize(text)\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "segments_ids = [0] * len(tokenized_text)\n",
    "# turn into torch tensor\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "with torch.no_grad(): # prediction\n",
    "    outputs = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 14, 30522])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = outputs[0]\n",
    "hidden_states = outputs[1]\n",
    "predictions.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['doctor', 0.7731055021286011],\n",
       " ['physician', 0.037808869034051895],\n",
       " ['man', 0.02467213198542595],\n",
       " ['nurse', 0.0221880991011858],\n",
       " ['surgeon', 0.019407344982028008],\n",
       " ['officer', 0.007634335197508335],\n",
       " ['captain', 0.007233228534460068],\n",
       " ['patient', 0.006821869872510433],\n",
       " ['professor', 0.003449886804446578],\n",
       " ['president', 0.0032858734484761953]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_index = tokenized_text.index('[MASK]')\n",
    "predicted_index = torch.argmax(predictions[0, masked_index]).item()\n",
    "predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])[0]\n",
    "\n",
    "# add softmax on the returned logits (prediction scores)\n",
    "prob = F.softmax(predictions[0, masked_index], dim = 0)\n",
    "# select topk prediction candidates\n",
    "prob_predicted_values, prob_predicted_indices = prob.topk(TOPK, dim=0, largest=True, sorted=True)\n",
    "word_cands = []\n",
    "\n",
    "for i in range(TOPK):\n",
    "  cur_predicted_token = tokenizer.convert_ids_to_tokens([prob_predicted_indices[i].item()])[0]\n",
    "  tmp = []\n",
    "  tmp.append(cur_predicted_token)\n",
    "  tmp.append(prob_predicted_values[i].item())\n",
    "  word_cands.append(tmp)\n",
    "word_cands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
